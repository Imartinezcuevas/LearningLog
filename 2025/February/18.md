Date: Tuesday, February 18, 2025

# What I learned today:

## DSA

- Adjacency list

Problems solved:

- 207 . Course Schedule
- 

## Explainable machine learning

Interpretable models are those that a human is able to understand without any help.
- Linear models
- Decision trees/rule-based

Regularized/Penalized Regression: Try to improve this type of models a little more, especially when there are many variables.
* Ridge
* Lasso

What happens when my models are complicated and I can't interpret them?
1. Explanatory methods

* Global method: try to give a complete explanation of the model.
* Local method: given an input, it is explained why that output is obtained. For that complete exit and entry. Just for those.

* Specific: The explanatory technique is only valid for a machine learning technique
* Agnostic: is independent of the ML technique used.

* Surrogate models: To give an explanation I am going to use a second machine learning model. To explain how a machine model works, another machine learning model is given.
For example, to explain a neural network, a surrogate model such as a decision tree is used.

2. LIME
First, it began to be used widely.

Lime = Local interpretable model-agnostic explanations.
* Local: fidelity to reflect the specific behaviour of the ML model in a specif situation.
* Interpretable: human being able to easily interpret what LIME provides.
* Model agnostic: for any kind of ML models. Only supervised models.

Lime intuition
6 Steps
1. Select input to explain
2. Generate samples. Perturbations of the reference.
3. Weight the samples according distance to reference
4. Predictions of  the samples
5. Train surrogate model -> dataset = samples + predictions. The model has to be interpretable.
6. Interpret surrogate model

## Maths
Revision:
- Equations with many solutions and no solutions
- Combining the rules of exponents with algebraic expressions.
- The 45-45-90 Triangle
- Compound and inequalities