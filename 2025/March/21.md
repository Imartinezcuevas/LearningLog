Date: Friday, March 21, 2025

# What I learned today:

## Federated Learning
Federated Learning (FL) is a Machine Learning (ML) paradigm introduced by Google in 2016. Its main goal is to address issues related to sharing sensitive data for training ML models, maintaining data in centralized silos, and the high costs of transmitting large amounts of data.

Federated Learning is an ML paradigm where collaborative models are trained in a privacy-preserving manner by aggregating models that have been locally trained by clients. In FL, data remains on local devices, and only model updates or gradients are transmitted.

### FL Lifecycle
The typical FL process follows these steps:

1. A participant (usually an aggregation server) decides on the model that all clients will use.
2. Each participant trains a local model using only their private data.
3. Each participant shares their local model weights.
4. The weights are aggregated centrally (or in a distributed manner) to create a global model.
5. The global model is downloaded by each client.
6. Steps 2 to 5 are repeated until the model converges.

### Benefits of FL
Federated Learning offers several advantages:
* Knowledge Sharing: The knowledge contained in local models is exchanged among federation participants.
* Privacy: Data remains on local devices; only model updates or gradients are transmitted.
* Communication Efficiency: Bandwidth usage is reduced since model weights are typically lighter than datasets.

### Differences from Traditional ML
Federated Learning differs from traditional ML in several ways:
* Centralized ML: Data is collected on a central server for training and is sent from clients for the training process (lacking data privacy).
* Local ML: Training is based on local data (without knowledge sharing, which negatively impacts heterogeneous scenarios) and may suffer from data scarcity.

### Distributed Learning vs. Federated Learning
Although both involve multiple nodes, key differences exist:
* Distributed Learning: The goal is to accelerate training and efficiently scale ML models by distributing workloads across multiple machines. The model can be split among nodes, but data can still be collected centrally.
* Federated Learning: The goal is to train models collaboratively while preserving privacy. Data remains on local devices, and each node has its own model. Data never leaves the nodes, and only model updates are shared. Scalability is limited to distributed computing clusters in distributed learning, whereas federated learning is highly scalable across diverse devices.

### Escenarios y Arquitecturas de FL
FL presents three scenarios based on participant data characteristics:
* Horizontal Federated Learning (HFL): Participants share the same feature set but different samples. A use case is learning user keyboard behavior and word selection.
* Vertical Federated Learning (VFL): Participants share the same samples but different feature sets. A use case is organizations collaborating to improve services.
* Federated Transfer Learning (FTL): Participants share only a small subset of samples and features. A use case is organizations with a limited overlap of samples and features.

These scenarios differ in terms of data distribution, privacy, collaboration scope, and computational requirements.
The training protocol can be implemented following three architectural approaches:
* Centralized (CFL): A single aggregator acts as the central server, while others are trainers. It is the most widely used due to its simplicity but has disadvantages such as a single point of failure and a potential bottleneck in large networks.
* Semi-Decentralized (SDFL): Similar to CFL, but the aggregator node changes in each training round, adding a bit more security.
* Decentralized (DFL): The aggregation task is distributed among federation participants, providing resilience against attacks and failures but introducing complexity in model management, synchronization, and communication.

Within Decentralized Federated Learning (DFL), two types of federations exist based on scale and node nature:
* Cross-Device: Involves a large number of nodes (>100), each with thousands of samples, limited computing power, and potential periodic disconnections.
* Cross-Silo: Involves fewer nodes (<100), usually organizations or data centers with millions of samples, robust and scalable computing, and high network capacity.

In DFL, participants can assume different roles:
* Trainer: Trains a local model and transmits it to neighbors.
* Aggregator: Receives and aggregates parameters to transmit to neighbors.
* Proxy: Forwards received model parameters to neighboring nodes.
* Inactive: Does not participate in the federation at a given time.

The network topology in DFL varies, affecting communication cost, robustness, and fault tolerance:
* Fully Connected: High communication cost and complexity.
* Partially Connected:
    * Star: Linear communication cost, low fault tolerance, and a bottleneck in the central node.
    * Ring: Higher transmission delays as nodes increase.
    * Random: High flexibility and moderate fault tolerance.
* Node Clustering: Based on local model similarity or using proxy nodes to interconnect different topologies.

The communication scheme in DFL can be:
* Synchronous: Nodes perform local training, and parameters are exchanged at synchronization points, potentially leading to slow convergence due to waiting times.
* Asynchronous: Independent parameter transmission and reception, offering faster convergence but higher costs and lower generalization due to model desynchronization.
* Semi-Synchronous: Local training continues until a predefined synchronization point.

### DistribuciÃ³n de los datos
Data distribution among clients is a crucial factor in FL:
* IID (Independent and Identically Distributed): Data is uniformly distributed among all clients, and each client has a representative sample of the global dataset.
* Non-IID (Non-Independent and Identically Distributed): Data is not uniformly distributed, and each client has unique, biased data based on its environment.

Non-IID data presents challenges such as model convergence issues and greater variability among models. Techniques to address this include clustering clients based on data similarity, personalizing local models, and adjusting aggregation weights.

### Challenges in FL
Federated Learning faces several challenges:
* Attacks and Countermeasures: Vulnerability to adversarial attacks (poisoning, inference). Solutions include differential privacy, secure aggregation, and anomaly detection.
* Performance with Non-IID Data: Slow convergence and biased models. Solutions include personalized federated learning, adaptive client selection, and data augmentation.
* Trust and Reputation: Malicious or low-quality client behavior. Solutions include trust evaluation tools and reputation systems.
* Model Optimization and Compression: Communication overhead and computational costs. Solutions include model pruning, quantization, and knowledge distillation.

### Security in Federated Learning
Security is a fundamental concern in FL, particularly regarding adversarial attacks.
* Adversarial Attacks: FL models are particularly vulnerable to poisoning and inference attacks. These attacks can be continuous, one-shot, or stealthy, originating from inside (malicious participants) or outside the federation.
* Poisoning Attacks: Attempt to modify the target model's behavior. They can be data poisoning (modifying features or labels) or model poisoning (modifying weights or gradients). 
* Inference Attacks: Executed during testing to learn labels, training data, the model, or its predictions. These include model inversion attacks, membership attacks, and topology/role attacks.

## System desing
Start reading "System Desing Intervew An Insider's Guide" by Alex Xu

We start with something simple, everything is running in a single server.
1. User access websites through domain names.
2. Internet protocol address is returned to the browser.
3. Once the IP address is obtained, HTTP requests are sent directly to the web server.
4. The server return HTML pages or JSON response for rendering.

### Database
With the growth of the user base, one server is not enought, and we need multiple servers. Separating web/mobile traffic and database servers allows them to be scaled independently.

We can choose between a traditional relational database and a non-relational database.
* Relational databases are also called a relational database management system (RDBMS) or SQL database. Relational databases represent and store data in tables and rows. You can perform join operations using SQL across different database tables.
* Non-Relational databases are also called NoSQL databases. These databases are grouped into four categories: key-value stores, graph stores, column stores, and document stores. Join operations are generally not supported in non-relational databases.

Non-relational databases might be the right choice if:
* Your application requires super-low latency.
* Your data are unstructured, or you don't have any relational data.
* You only need to serializae and deserialize data.
* You need to store a massice amount of data.

### Vertical scaling vs horizontal scaling
Vertical scaling, referred to as "scaled up", means the process of adding more power to your servers. Horizontal scaling, referred to as "scale-out", allows you to scale by adding more servers into the pool of servers.

When traffic is low, vertical scaling is a great option. Unfortunately, it come with limitations:
* Vertical scaling has a hard limit. It is impossible to add unlimited CPU and memory to a single server.
* Vertical scaling does not have failover and redundancy. If one server goes down, the website/app goes down with it completely.

If many users access the web server simultaneously and it reaches the web server's load limit, users generally experience slower response or fail to connect to the server. A load balancer is the best technique to address these problems.

### Load balancer
A load balancer evenly distributes incoming traffic among web srevers that are defined in a load balanced set. Users connect to the public IP of the load balancer directly. With this setup, web servers are unreachable directly by clients anymore.

After a load balancer and a second web server are added, we successfully solved no failover issue and improve the availability of the web tier.

### Database replication
Database replication can be used in many database management systems, usually with a master/slave relationship between the original (master) and the copies (slaves).

A master database generally only supports write operations. A slave database gets copies of the data from the msater and only support read operations. All the data-modifying commands must be sent to the master database. Most applications require a much higher ratio of reads to writes; thus, the namer of slaves in a system is usually larger than the number of master databases.

Advantages of database replication:
* Better performance: in the master-slave model, all write and updates happend in master nodes; whereas, read operations are distributed across slave nodes. This model improves performance because it allos more queries to be processed in parallel.
* Reliability: if one of your databases servers is destroyed, data is still preserved. You do not need to worry about data loss because data is replicated across multiple locations.
* High availability: by replicating data across different locations, your website/app remains in operations even if a database is offline as you can access data stored in another database.

What if one of the databases goes offline?
* if only one slave is available and it goes offline, read operations will be directed to the master database temporarily. As soon as the issue is found, a new slave database will replace the old one.
* If the master goes offline, a slave databse will be promoted to be the new master. All the database operations will be temporarily executed on the new master database. A new slave database will replace the old one for data replication immediately. In production systems, promoting a new master is more complicated as the data in a slave database might not be up to date. The missing data needs to be updated by running data recovery scripts.